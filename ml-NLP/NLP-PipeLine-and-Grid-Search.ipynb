{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "from pprint import pprint\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "df_spam_collection = pd.read_csv('SpamCollection', sep='\\t', names=['response','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  response                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view first 5 records with head method\n",
    "df_spam_collection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import text processing libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# import SGD classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# import for grid search\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# import for pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# definE the pipeline\n",
    "pipeline = Pipeline([\n",
    "       ('vect', CountVectorizer()),\n",
    "       ('tfidf', TfidfTransformer()),\n",
    "       ('clf', SGDClassifier())\n",
    "      \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for grid search\n",
    "parameters = {'tfidf_use_idf':(True,False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing grid search now...\n",
      "parameters: \n",
      "{'tfidf_use_idf': (True, False)}\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000000002256F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000000002256F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(616, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(616, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (616, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=616, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 8, 5, 25, 11, 617176, tzinfo=tzutc()), 'msg_id': '2aa649acdf5d4d7c8bf4f61651ae7fe9', 'msg_type': 'execute_request', 'session': 'fb243734193c45d78f88af5189346f15', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '2aa649acdf5d4d7c8bf4f61651ae7fe9', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'fb243734193c45d78f88af5189346f15']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 8, 5, 25, 11, 617176, tzinfo=tzutc()), 'msg_id': '2aa649acdf5d4d7c8bf4f61651ae7fe9', 'msg_type': 'execute_request', 'session': 'fb243734193c45d78f88af5189346f15', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '2aa649acdf5d4d7c8bf4f61651ae7fe9', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'fb243734193c45d78f88af5189346f15'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 8, 5, 25, 11, 617176, tzinfo=tzutc()), 'msg_id': '2aa649acdf5d4d7c8bf4f61651ae7fe9', 'msg_type': 'execute_request', 'session': 'fb243734193c45d78f88af5189346f15', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '2aa649acdf5d4d7c8bf4f61651ae7fe9', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-13-2384ac69d7d5>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 80a5710, execution_co...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000000008204660, file \"<ipython-input-13-2384ac69d7d5>\", line 7>\n        result = <ExecutionResult object at 80a5710, execution_co...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000000008204660, file \"<ipython-input-13-2384ac69d7d5>\", line 7>, result=<ExecutionResult object at 80a5710, execution_co...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000000008204660, file \"<ipython-input-13-2384ac69d7d5>\", line 7>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', '#import required libraries\\nimport pandas as pd\\ni...g\\nfrom pprint import pprint\\nfrom time import time', \"# import the dataset\\ndf_spam_collection = pd.rea...spam.csv', sep='\\\\t',names=['response','message'])\", \"# import the dataset\\ndf_spam_collection = pd.read_csv('spam.csv')\", \"# import the dataset\\ndf_spam_collection = pd.read_csv('spam.csv')\", \"# import the dataset\\ndf_spam_collection = pd.read_csv('SpamCollection')\", \"# import the dataset\\ndf_spam_collection = pd.rea...lection', sep='\\\\t', names=['response','message'])\", '# view first 5 records with head method\\ndf_spam_collection.head()', \"# import text processing libraries\\nfrom sklearn....)),\\n       ('clf', SGDClassifier())\\n      \\n    ])\", \"# parameters for grid search\\nparameters = {'tfidf_use_idf':(True,False)}\", \"# perform the grid search with pipeline and para...e'])\\nprint('done in %0.3fs'% (time()-t0))\\nprint()\", \"# perform the grid search with pipeline and para...e'])\\nprint('done in %0.3fs'% (time()-t0))\\nprint()\", \"# perform the grid search with pipeline and para...])\\nprint('done in %0.3fs'% (time()-t0))\\nprint('')\", \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\"], 'Out': {7:   response                                      ...Nah I don't think he goes to usf, he lives aro...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, '_':   response                                      ...Nah I don't think he goes to usf, he lives aro..., '_7':   response                                      ...Nah I don't think he goes to usf, he lives aro..., '__': '', ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', '#import required libraries\\nimport pandas as pd\\ni...g\\nfrom pprint import pprint\\nfrom time import time', \"# import the dataset\\ndf_spam_collection = pd.rea...spam.csv', sep='\\\\t',names=['response','message'])\", \"# import the dataset\\ndf_spam_collection = pd.read_csv('spam.csv')\", \"# import the dataset\\ndf_spam_collection = pd.read_csv('spam.csv')\", \"# import the dataset\\ndf_spam_collection = pd.read_csv('SpamCollection')\", \"# import the dataset\\ndf_spam_collection = pd.rea...lection', sep='\\\\t', names=['response','message'])\", '# view first 5 records with head method\\ndf_spam_collection.head()', \"# import text processing libraries\\nfrom sklearn....)),\\n       ('clf', SGDClassifier())\\n      \\n    ])\", \"# parameters for grid search\\nparameters = {'tfidf_use_idf':(True,False)}\", \"# perform the grid search with pipeline and para...e'])\\nprint('done in %0.3fs'% (time()-t0))\\nprint()\", \"# perform the grid search with pipeline and para...e'])\\nprint('done in %0.3fs'% (time()-t0))\\nprint()\", \"# perform the grid search with pipeline and para...])\\nprint('done in %0.3fs'% (time()-t0))\\nprint('')\", \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\"], 'Out': {7:   response                                      ...Nah I don't think he goes to usf, he lives aro...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, '_':   response                                      ...Nah I don't think he goes to usf, he lives aro..., '_7':   response                                      ...Nah I don't think he goes to usf, he lives aro..., '__': '', ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\rahul.pant\\Desktop\\07-jan-2018\\ml-NLP\\<ipython-input-13-2384ac69d7d5> in <module>()\n      2 grid_search = GridSearchCV(pipeline,parameters,n_jobs=-1,verbose=1)\n      3 print('performing grid search now...')\n      4 print('parameters: ')\n      5 pprint(parameters)\n      6 t0 = time()\n----> 7 grid_search.fit(df_spam_collection['message'],df_spam_collection['response'])\n      8 print('done in %0.3fs' % (time()-t0))\n      9 print('')\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring=None, verbose=1), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object)\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=1)>\n        X = 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object\n        y = 0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object\n        self.param_grid = {'tfidf_use_idf': (True, False)}\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring=None, verbose=1), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Jan  8 10:55:14 2019\nPID: 7792                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 1, {'tfidf_use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 1, {'tfidf_use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, scorer=<function _passthrough_scorer>, train=array([1767, 1777, 1778, ..., 5569, 5570, 5571]), test=array([   0,    1,    2, ..., 1866, 1867, 1868]), verbose=1, parameters={'tfidf_use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1659     fit_params = fit_params if fit_params is not None else {}\n   1660     fit_params = dict([(k, _index_param_value(X, v, train))\n   1661                       for k, v in fit_params.items()])\n   1662 \n   1663     if parameters is not None:\n-> 1664         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'tfidf_use_idf': True}\n   1665 \n   1666     start_time = time.time()\n   1667 \n   1668     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'tfidf_use_idf': True})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'tfidf_use_idf': True}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'tfidf_use_idf': True})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'tfidf_use_idf': True}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), **params={'tfidf_use_idf': True})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'tfidf_use_idf'\n        self = Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter tfidf_use_idf for estimator Pipeline(memory=None,\n     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip...='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py\", line 1664, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 142, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 49, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 274, in set_params\n    (key, self))\nValueError: Invalid parameter tfidf_use_idf for estimator Pipeline(memory=None,\n     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip...='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Jan  8 10:55:14 2019\nPID: 7792                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 1, {'tfidf_use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 1, {'tfidf_use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, scorer=<function _passthrough_scorer>, train=array([1767, 1777, 1778, ..., 5569, 5570, 5571]), test=array([   0,    1,    2, ..., 1866, 1867, 1868]), verbose=1, parameters={'tfidf_use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1659     fit_params = fit_params if fit_params is not None else {}\n   1660     fit_params = dict([(k, _index_param_value(X, v, train))\n   1661                       for k, v in fit_params.items()])\n   1662 \n   1663     if parameters is not None:\n-> 1664         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'tfidf_use_idf': True}\n   1665 \n   1666     start_time = time.time()\n   1667 \n   1668     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'tfidf_use_idf': True})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'tfidf_use_idf': True}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'tfidf_use_idf': True})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'tfidf_use_idf': True}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), **params={'tfidf_use_idf': True})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'tfidf_use_idf'\n        self = Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter tfidf_use_idf for estimator Pipeline(memory=None,\n     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip...='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Jan  8 10:55:14 2019\nPID: 7792                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 1, {'tfidf_use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 1, {'tfidf_use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, scorer=<function _passthrough_scorer>, train=array([1767, 1777, 1778, ..., 5569, 5570, 5571]), test=array([   0,    1,    2, ..., 1866, 1867, 1868]), verbose=1, parameters={'tfidf_use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1659     fit_params = fit_params if fit_params is not None else {}\n   1660     fit_params = dict([(k, _index_param_value(X, v, train))\n   1661                       for k, v in fit_params.items()])\n   1662 \n   1663     if parameters is not None:\n-> 1664         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'tfidf_use_idf': True}\n   1665 \n   1666     start_time = time.time()\n   1667 \n   1668     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'tfidf_use_idf': True})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'tfidf_use_idf': True}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'tfidf_use_idf': True})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'tfidf_use_idf': True}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), **params={'tfidf_use_idf': True})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'tfidf_use_idf'\n        self = Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter tfidf_use_idf for estimator Pipeline(memory=None,\n     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip...='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2384ac69d7d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_spam_collection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_spam_collection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'response'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'done in %0.3fs'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \"\"\"\n\u001b[1;32m--> 838\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[0;32m    572\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                                     error_score=self.error_score)\n\u001b[1;32m--> 574\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m                 for train, test in cv)\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x0000000002256F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x0000000002256F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\__pycache__\\ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\ProgramD...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    417             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    418                                    finalizer=self._asyncgen_finalizer_hook)\n    419         try:\n    420             events._set_running_loop(self)\n    421             while True:\n--> 422                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    423                 if self._stopping:\n    424                     break\n    425         finally:\n    426             self._stopping = False\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1427                         logger.warning('Executing %s took %.3f seconds',\n   1428                                        _format_handle(handle), dt)\n   1429                 finally:\n   1430                     self._current_handle = None\n   1431             else:\n-> 1432                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(616, 1)>>\n   1433         handle = None  # Needed to break cycles when an exception occurs.\n   1434 \n   1435     def _set_coroutine_wrapper(self, enabled):\n   1436         try:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(616, 1)>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (616, 1)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=616, events=1)\n    112             self.writers.remove(fd)\n    113         del self.handlers[fd]\n    114 \n    115     def _handle_events(self, fd, events):\n    116         fileobj, handler_func = self.handlers[fd]\n--> 117         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    118 \n    119     def start(self):\n    120         try:\n    121             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 8, 5, 25, 11, 617176, tzinfo=tzutc()), 'msg_id': '2aa649acdf5d4d7c8bf4f61651ae7fe9', 'msg_type': 'execute_request', 'session': 'fb243734193c45d78f88af5189346f15', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '2aa649acdf5d4d7c8bf4f61651ae7fe9', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'fb243734193c45d78f88af5189346f15']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 8, 5, 25, 11, 617176, tzinfo=tzutc()), 'msg_id': '2aa649acdf5d4d7c8bf4f61651ae7fe9', 'msg_type': 'execute_request', 'session': 'fb243734193c45d78f88af5189346f15', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '2aa649acdf5d4d7c8bf4f61651ae7fe9', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'fb243734193c45d78f88af5189346f15'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2019, 1, 8, 5, 25, 11, 617176, tzinfo=tzutc()), 'msg_id': '2aa649acdf5d4d7c8bf4f61651ae7fe9', 'msg_type': 'execute_request', 'session': 'fb243734193c45d78f88af5189346f15', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '2aa649acdf5d4d7c8bf4f61651ae7fe9', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\", store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\"\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\", store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-13-2384ac69d7d5>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 80a5710, execution_co...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x0000000008204660, file \"<ipython-input-13-2384ac69d7d5>\", line 7>\n        result = <ExecutionResult object at 80a5710, execution_co...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x0000000008204660, file \"<ipython-input-13-2384ac69d7d5>\", line 7>, result=<ExecutionResult object at 80a5710, execution_co...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x0000000008204660, file \"<ipython-input-13-2384ac69d7d5>\", line 7>\n        self.user_global_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', '#import required libraries\\nimport pandas as pd\\ni...g\\nfrom pprint import pprint\\nfrom time import time', \"# import the dataset\\ndf_spam_collection = pd.rea...spam.csv', sep='\\\\t',names=['response','message'])\", \"# import the dataset\\ndf_spam_collection = pd.read_csv('spam.csv')\", \"# import the dataset\\ndf_spam_collection = pd.read_csv('spam.csv')\", \"# import the dataset\\ndf_spam_collection = pd.read_csv('SpamCollection')\", \"# import the dataset\\ndf_spam_collection = pd.rea...lection', sep='\\\\t', names=['response','message'])\", '# view first 5 records with head method\\ndf_spam_collection.head()', \"# import text processing libraries\\nfrom sklearn....)),\\n       ('clf', SGDClassifier())\\n      \\n    ])\", \"# parameters for grid search\\nparameters = {'tfidf_use_idf':(True,False)}\", \"# perform the grid search with pipeline and para...e'])\\nprint('done in %0.3fs'% (time()-t0))\\nprint()\", \"# perform the grid search with pipeline and para...e'])\\nprint('done in %0.3fs'% (time()-t0))\\nprint()\", \"# perform the grid search with pipeline and para...])\\nprint('done in %0.3fs'% (time()-t0))\\nprint('')\", \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\"], 'Out': {7:   response                                      ...Nah I don't think he goes to usf, he lives aro...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, '_':   response                                      ...Nah I don't think he goes to usf, he lives aro..., '_7':   response                                      ...Nah I don't think he goes to usf, he lives aro..., '__': '', ...}\n        self.user_ns = {'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GridSearchCV': <class 'sklearn.grid_search.GridSearchCV'>, 'In': ['', '#import required libraries\\nimport pandas as pd\\ni...g\\nfrom pprint import pprint\\nfrom time import time', \"# import the dataset\\ndf_spam_collection = pd.rea...spam.csv', sep='\\\\t',names=['response','message'])\", \"# import the dataset\\ndf_spam_collection = pd.read_csv('spam.csv')\", \"# import the dataset\\ndf_spam_collection = pd.read_csv('spam.csv')\", \"# import the dataset\\ndf_spam_collection = pd.read_csv('SpamCollection')\", \"# import the dataset\\ndf_spam_collection = pd.rea...lection', sep='\\\\t', names=['response','message'])\", '# view first 5 records with head method\\ndf_spam_collection.head()', \"# import text processing libraries\\nfrom sklearn....)),\\n       ('clf', SGDClassifier())\\n      \\n    ])\", \"# parameters for grid search\\nparameters = {'tfidf_use_idf':(True,False)}\", \"# perform the grid search with pipeline and para...e'])\\nprint('done in %0.3fs'% (time()-t0))\\nprint()\", \"# perform the grid search with pipeline and para...e'])\\nprint('done in %0.3fs'% (time()-t0))\\nprint()\", \"# perform the grid search with pipeline and para...])\\nprint('done in %0.3fs'% (time()-t0))\\nprint('')\", \"# perform the grid search with pipeline and para...)\\nprint('done in %0.3fs' % (time()-t0))\\nprint('')\"], 'Out': {7:   response                                      ...Nah I don't think he goes to usf, he lives aro...}, 'Pipeline': <class 'sklearn.pipeline.Pipeline'>, 'SGDClassifier': <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'>, 'TfidfTransformer': <class 'sklearn.feature_extraction.text.TfidfTransformer'>, '_':   response                                      ...Nah I don't think he goes to usf, he lives aro..., '_7':   response                                      ...Nah I don't think he goes to usf, he lives aro..., '__': '', ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\rahul.pant\\Desktop\\07-jan-2018\\ml-NLP\\<ipython-input-13-2384ac69d7d5> in <module>()\n      2 grid_search = GridSearchCV(pipeline,parameters,n_jobs=-1,verbose=1)\n      3 print('performing grid search now...')\n      4 print('parameters: ')\n      5 pprint(parameters)\n      6 t0 = time()\n----> 7 grid_search.fit(df_spam_collection['message'],df_spam_collection['response'])\n      8 print('done in %0.3fs' % (time()-t0))\n      9 print('')\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring=None, verbose=1), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object)\n    833         y : array-like, shape = [n_samples] or [n_samples, n_output], optional\n    834             Target relative to X for classification or regression;\n    835             None for unsupervised learning.\n    836 \n    837         \"\"\"\n--> 838         return self._fit(X, y, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...'2*n_jobs', refit=True, scoring=None, verbose=1)>\n        X = 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object\n        y = 0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object\n        self.param_grid = {'tfidf_use_idf': (True, False)}\n    839 \n    840 \n    841 class RandomizedSearchCV(BaseSearchCV):\n    842     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py in _fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...='2*n_jobs', refit=True, scoring=None, verbose=1), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, parameter_iterable=<sklearn.grid_search.ParameterGrid object>)\n    569         )(\n    570             delayed(_fit_and_score)(clone(base_estimator), X, y, self.scorer_,\n    571                                     train, test, self.verbose, parameters,\n    572                                     self.fit_params, return_parameters=True,\n    573                                     error_score=self.error_score)\n--> 574                 for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.grid_search.ParameterGrid object>\n    575                 for train, test in cv)\n    576 \n    577         # Out is a list of triplet: score, estimator, n_test_samples\n    578         n_fits = len(out)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Jan  8 10:55:14 2019\nPID: 7792                 Python 3.6.5: C:\\ProgramData\\Anaconda3\\python.exe\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 1, {'tfidf_use_idf': True}, {}), {'error_score': 'raise', 'return_parameters': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), 0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, 0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, <function _passthrough_scorer>, array([1767, 1777, 1778, ..., 5569, 5570, 5571]), array([   0,    1,    2, ..., 1866, 1867, 1868]), 1, {'tfidf_use_idf': True}, {})\n        kwargs = {'error_score': 'raise', 'return_parameters': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), X=0       Go until jurong point, crazy.. Available...s name\nName: message, Length: 5572, dtype: object, y=0        ham\n1        ham\n2       spam\n3        ...  ham\nName: response, Length: 5572, dtype: object, scorer=<function _passthrough_scorer>, train=array([1767, 1777, 1778, ..., 5569, 5570, 5571]), test=array([   0,    1,    2, ..., 1866, 1867, 1868]), verbose=1, parameters={'tfidf_use_idf': True}, fit_params={}, return_train_score=False, return_parameters=True, error_score='raise')\n   1659     fit_params = fit_params if fit_params is not None else {}\n   1660     fit_params = dict([(k, _index_param_value(X, v, train))\n   1661                       for k, v in fit_params.items()])\n   1662 \n   1663     if parameters is not None:\n-> 1664         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        parameters = {'tfidf_use_idf': True}\n   1665 \n   1666     start_time = time.time()\n   1667 \n   1668     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), **kwargs={'tfidf_use_idf': True})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...=True, tol=None, verbose=0, warm_start=False))])>\n        kwargs = {'tfidf_use_idf': True}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), attr='steps', **params={'tfidf_use_idf': True})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...=True, tol=None, verbose=0, warm_start=False))])>\n        params = {'tfidf_use_idf': True}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))]), **params={'tfidf_use_idf': True})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'tfidf_use_idf'\n        self = Pipeline(memory=None,\n     steps=[('vect', Count...e=True, tol=None, verbose=0, warm_start=False))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter tfidf_use_idf for estimator Pipeline(memory=None,\n     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip...='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "# perform the grid search with pipeline and parameters\n",
    "grid_search = GridSearchCV(pipeline,parameters,n_jobs=-1,verbose=1)\n",
    "print('performing grid search now...')\n",
    "print('parameters: ')\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(df_spam_collection['message'],df_spam_collection['response'])\n",
    "print('done in %0.3fs' % (time()-t0))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
